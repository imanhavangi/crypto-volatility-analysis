import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter

def analyze_data_distribution(training_file='training_data.csv'):
    """
    ØªØ­Ù„ÛŒÙ„ ØªÙˆØ²ÛŒØ¹ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ùˆ Ø¨Ø±Ø±Ø³ÛŒ class imbalance
    """
    print("ðŸ” Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ùˆ ØªØ­Ù„ÛŒÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§...")
    
    # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
    df = pd.read_csv(training_file)
    
    print(f"ðŸ“Š ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§: {len(df)}")
    print(f"ðŸ“Š ØªØ¹Ø¯Ø§Ø¯ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§: {df.shape[1]}")
    
    # Ø¨Ø±Ø±Ø³ÛŒ Ù…Ù‚Ø§Ø¯ÛŒØ± null
    print(f"\nâŒ Ù…Ù‚Ø§Ø¯ÛŒØ± null:\n{df.isnull().sum()}")
    
    # ØªØ­Ù„ÛŒÙ„ ØªÙˆØ²ÛŒØ¹ Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ÛŒ Ù‡Ø¯Ù
    print("\n" + "="*50)
    print("ðŸŽ¯ ØªØ­Ù„ÛŒÙ„ ØªÙˆØ²ÛŒØ¹ Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ÛŒ Ù‡Ø¯Ù")
    print("="*50)
    
    # Entry prediction analysis
    entry_counts = df['is_optimal_entry'].value_counts()
    entry_ratio = entry_counts / len(df) * 100
    
    print(f"\nðŸ“ˆ Entry Prediction Distribution:")
    print(f"   False (0): {entry_counts[False]:,} ({entry_ratio[False]:.2f}%)")
    print(f"   True (1):  {entry_counts[True]:,} ({entry_ratio[True]:.2f}%)")
    print(f"   Imbalance Ratio: {entry_counts[False] / entry_counts[True]:.1f}:1")
    
    # Exit prediction analysis
    exit_counts = df['is_optimal_exit'].value_counts()
    exit_ratio = exit_counts / len(df) * 100
    
    print(f"\nðŸ“‰ Exit Prediction Distribution:")
    print(f"   False (0): {exit_counts[False]:,} ({exit_ratio[False]:.2f}%)")
    print(f"   True (1):  {exit_counts[True]:,} ({exit_ratio[True]:.2f}%)")
    print(f"   Imbalance Ratio: {exit_counts[False] / exit_counts[True]:.1f}:1")
    
    # Future profit analysis
    print(f"\nðŸ’° Future Profit Potential Analysis:")
    profit_stats = df['future_profit_potential'].describe()
    print(profit_stats)
    
    positive_profit = (df['future_profit_potential'] > 0).sum()
    zero_profit = (df['future_profit_potential'] == 0).sum()
    negative_profit = (df['future_profit_potential'] < 0).sum()
    
    print(f"\n   Positive Profit: {positive_profit:,} ({positive_profit/len(df)*100:.2f}%)")
    print(f"   Zero Profit:     {zero_profit:,} ({zero_profit/len(df)*100:.2f}%)")
    print(f"   Negative Profit: {negative_profit:,} ({negative_profit/len(df)*100:.2f}%)")
    
    # ØªØ±Ø³ÛŒÙ… Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§
    plt.figure(figsize=(15, 10))
    
    # Entry prediction distribution
    plt.subplot(2, 3, 1)
    entry_counts.plot(kind='bar', color=['lightcoral', 'lightgreen'])
    plt.title('Entry Prediction Distribution')
    plt.xlabel('is_optimal_entry')
    plt.ylabel('Count')
    plt.xticks(rotation=0)
    
    # Exit prediction distribution
    plt.subplot(2, 3, 2)
    exit_counts.plot(kind='bar', color=['lightcoral', 'lightblue'])
    plt.title('Exit Prediction Distribution')
    plt.xlabel('is_optimal_exit')
    plt.ylabel('Count')
    plt.xticks(rotation=0)
    
    # Future profit histogram
    plt.subplot(2, 3, 3)
    plt.hist(df['future_profit_potential'], bins=50, alpha=0.7, color='purple')
    plt.title('Future Profit Potential Distribution')
    plt.xlabel('Future Profit Potential')
    plt.ylabel('Frequency')
    
    # Correlation heatmap of target variables
    plt.subplot(2, 3, 4)
    target_corr = df[['is_optimal_entry', 'is_optimal_exit', 'future_profit_potential']].corr()
    sns.heatmap(target_corr, annot=True, cmap='coolwarm', center=0)
    plt.title('Target Variables Correlation')
    
    # Combined entry/exit analysis
    plt.subplot(2, 3, 5)
    combined_analysis = pd.crosstab(df['is_optimal_entry'], df['is_optimal_exit'], margins=True)
    sns.heatmap(combined_analysis.iloc[:-1, :-1], annot=True, fmt='d', cmap='Blues')
    plt.title('Entry vs Exit Cross-tabulation')
    
    # Feature importance analysis (RSI as example)
    plt.subplot(2, 3, 6)
    plt.scatter(df['rsi'], df['future_profit_potential'], alpha=0.1, s=1)
    plt.xlabel('RSI')
    plt.ylabel('Future Profit Potential')
    plt.title('RSI vs Future Profit')
    
    plt.tight_layout()
    plt.savefig('data_distribution_analysis.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    # Ù…Ø­Ø§Ø³Ø¨Ù‡ ÙˆØ²Ù†â€ŒÙ‡Ø§ÛŒ Ú©Ù„Ø§Ø³ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„
    print("\n" + "="*50)
    print("âš–ï¸  Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ ÙˆØ²Ù†â€ŒÙ‡Ø§ÛŒ Ú©Ù„Ø§Ø³ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„")
    print("="*50)
    
    # Class weights for entry prediction
    total_entry = len(df)
    weight_entry_0 = total_entry / (2 * entry_counts[False])
    weight_entry_1 = total_entry / (2 * entry_counts[True])
    
    print(f"\nðŸ“ˆ Entry Prediction Class Weights:")
    print(f"   Class 0 (False): {weight_entry_0:.4f}")
    print(f"   Class 1 (True):  {weight_entry_1:.4f}")
    
    # Class weights for exit prediction
    weight_exit_0 = total_entry / (2 * exit_counts[False])
    weight_exit_1 = total_entry / (2 * exit_counts[True])
    
    print(f"\nðŸ“‰ Exit Prediction Class Weights:")
    print(f"   Class 0 (False): {weight_exit_0:.4f}")
    print(f"   Class 1 (True):  {weight_exit_1:.4f}")
    
    return {
        'entry_weights': {0: weight_entry_0, 1: weight_entry_1},
        'exit_weights': {0: weight_exit_0, 1: weight_exit_1},
        'entry_counts': entry_counts,
        'exit_counts': exit_counts,
        'data_shape': df.shape
    }

def suggest_improvements():
    """
    Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ø¨Ø±Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ Ù…Ø¯Ù„
    """
    print("\n" + "="*60)
    print("ðŸ’¡ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯Ø§Øª Ø¨Ø±Ø§ÛŒ Ø­Ù„ Ù…Ø´Ú©Ù„ Class Imbalance")
    print("="*60)
    
    suggestions = [
        "1ï¸âƒ£  Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Class Weighting Ø¯Ø± Ù…Ø¯Ù„",
        "2ï¸âƒ£  Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ SMOTE Ø¨Ø±Ø§ÛŒ oversampling",
        "3ï¸âƒ£  ØªÙ†Ø¸ÛŒÙ… threshold Ø¨Ø±Ø§ÛŒ classification",
        "4ï¸âƒ£  Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Focal Loss Ø¨Ù‡ Ø¬Ø§ÛŒ Binary Crossentropy",
        "5ï¸âƒ£  Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ÛŒ Ù…Ù†Ø§Ø³Ø¨: F1-Score, AUC-ROC, Precision-Recall AUC",
        "6ï¸âƒ£  Stratified sampling Ø¯Ø± train/test split",
        "7ï¸âƒ£  Ensemble methods Ø¨Ø§ different thresholds"
    ]
    
    for suggestion in suggestions:
        print(suggestion)
    
    print(f"\nðŸŽ¯ Ø¨Ù‡ØªØ±ÛŒÙ† Ø±Ø§Ù‡â€ŒÚ©Ø§Ø±: ØªØ±Ú©ÛŒØ¨ Class Weighting + SMOTE + Ù…Ù†Ø§Ø³Ø¨â€ŒØªØ±ÛŒÙ† Threshold")

if __name__ == "__main__":
    analysis_results = analyze_data_distribution()
    suggest_improvements() 