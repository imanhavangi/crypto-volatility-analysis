import pandas as pd
import numpy as np
import tensorflow as tf
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings('ignore')

class ModelDiagnostic:
    def __init__(self):
        self.feature_columns = [
            'open', 'high', 'low', 'close', 'volume',
            'rsi', 'macd', 'macd_signal', 'macd_histogram',
            'bb_position', 'volatility_5m', 'volatility_15m',
            'volume_ratio', 'price_change_1m', 'price_change_5m',
            'price_change_15m', 'trend_strength', 'volatility_percentile',
            'volume_percentile'
        ]
        
    def prepare_test_data(self):
        """Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡ ØªØ³Øª"""
        print("ğŸ“‹ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ³Øª...")
        
        # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù†Ù…ÙˆÙ†Ù‡ Ø§Ø² training data
        df = pd.read_csv('training_data.csv', nrows=100)
        
        # Ø§Ù†ØªØ®Ø§Ø¨ ÙÛŒÚ†Ø±Ù‡Ø§
        features = df[self.feature_columns].fillna(0)
        
        # Ø§ÛŒØ¬Ø§Ø¯ scaler
        scaler = StandardScaler()
        features_scaled = scaler.fit_transform(features)
        
        print(f"âœ… Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ {len(features)} Ù†Ù…ÙˆÙ†Ù‡ Ø¯Ø§Ø¯Ù‡")
        return features_scaled, scaler
        
    def test_model(self, model_path, test_data, model_name):
        """ØªØ³Øª ÛŒÚ© Ù…Ø¯Ù„ Ø®Ø§Øµ"""
        print(f"\nğŸ” ØªØ³Øª Ù…Ø¯Ù„: {model_name}")
        print(f"ğŸ“ Ù…Ø³ÛŒØ±: {model_path}")
        
        try:
            # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„
            model = tf.keras.models.load_model(model_path)
            print(f"âœ… Ù…Ø¯Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯")
            
            # Ù†Ù…Ø§ÛŒØ´ Ø³Ø§Ø®ØªØ§Ø± Ù…Ø¯Ù„ (Ø³Ø§Ø¯Ù‡)
            print(f"ğŸ“Š Ø³Ø§Ø®ØªØ§Ø± Ù…Ø¯Ù„:")
            try:
                print(f"   Input shape: {model.input_shape}")
                print(f"   Output shape: {model.output_shape}")
            except:
                print(f"   Model loaded successfully")
            
            # ØªØ³Øª Ø¨Ø§ Ù†Ù…ÙˆÙ†Ù‡ Ø¯Ø§Ø¯Ù‡
            sample_size = min(10, len(test_data))
            predictions = []
            
            for i in range(sample_size):
                sample = test_data[i:i+1]  # ÛŒÚ© Ù†Ù…ÙˆÙ†Ù‡
                pred = model.predict(sample, verbose=0)
                predictions.append(pred)
            
            # ØªØ­Ù„ÛŒÙ„ Ù†ØªØ§ÛŒØ¬
            print(f"\nğŸ“ˆ Ù†ØªØ§ÛŒØ¬ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ ({sample_size} Ù†Ù…ÙˆÙ†Ù‡):")
            
            if isinstance(predictions[0], list):
                # Ú†Ù†Ø¯ Ø®Ø±ÙˆØ¬ÛŒ
                num_outputs = len(predictions[0])
                print(f"   ØªØ¹Ø¯Ø§Ø¯ Ø®Ø±ÙˆØ¬ÛŒâ€ŒÙ‡Ø§: {num_outputs}")
                
                for output_idx in range(num_outputs):
                    output_name = f"Output_{output_idx+1}"
                    if output_idx == 0:
                        output_name = "Entry"
                    elif output_idx == 1:
                        output_name = "Exit"
                    elif output_idx == 2:
                        output_name = "Profit"
                    
                    values = [pred[output_idx][0][0] for pred in predictions]
                    
                    print(f"   {output_name}:")
                    print(f"     Mean: {np.mean(values):.4f}")
                    print(f"     Std: {np.std(values):.4f}")
                    print(f"     Min/Max: {np.min(values):.4f}/{np.max(values):.4f}")
                    print(f"     Sample values: {[f'{v:.4f}' for v in values[:5]]}")
            else:
                # ÛŒÚ© Ø®Ø±ÙˆØ¬ÛŒ
                values = [pred[0][0] for pred in predictions]
                print(f"   Single Output:")
                print(f"     Mean: {np.mean(values):.4f}")
                print(f"     Std: {np.std(values):.4f}")
                print(f"     Min/Max: {np.min(values):.4f}/{np.max(values):.4f}")
                print(f"     Sample values: {[f'{v:.4f}' for v in values[:5]]}")
            
            return True, predictions
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªØ³Øª Ù…Ø¯Ù„: {e}")
            return False, None
    
    def run_diagnostic(self):
        """Ø§Ø¬Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ú©Ø§Ù…Ù„"""
        print("ğŸ”¬ Ø´Ø±ÙˆØ¹ ØªØ´Ø®ÛŒØµ Ù…Ø¯Ù„â€ŒÙ‡Ø§")
        print("="*50)
        
        # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ³Øª
        test_data, scaler = self.prepare_test_data()
        
        # ØªØ³Øª Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯
        models_to_test = [
            ('best_improved_model.h5', 'Improved Model'),
            ('best_trading_model.h5', 'Original Deep Learning Model')
        ]
        
        results = {}
        
        for model_path, model_name in models_to_test:
            success, predictions = self.test_model(model_path, test_data, model_name)
            results[model_name] = {
                'success': success,
                'predictions': predictions,
                'path': model_path
            }
        
        # Ø®Ù„Ø§ØµÙ‡ Ù†ØªØ§ÛŒØ¬
        print(f"\nğŸ“Š Ø®Ù„Ø§ØµÙ‡ Ù†ØªØ§ÛŒØ¬:")
        print("="*50)
        
        working_models = []
        for name, result in results.items():
            if result['success']:
                print(f"âœ… {name}: Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯")
                working_models.append((name, result['path']))
            else:
                print(f"âŒ {name}: Ù…Ø´Ú©Ù„ Ø¯Ø§Ø±Ø¯")
        
        if working_models:
            print(f"\nğŸ’¡ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯:")
            for name, path in working_models:
                print(f"   Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² {name}: {path}")
        else:
            print(f"\nâš ï¸ Ù‡ÛŒÚ† Ù…Ø¯Ù„ Ø³Ø§Ù„Ù…ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯! Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Ø¬Ø¯ÛŒØ¯")
        
        return results

if __name__ == "__main__":
    diagnostic = ModelDiagnostic()
    results = diagnostic.run_diagnostic() 